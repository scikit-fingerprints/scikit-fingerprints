{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbzeeN90YCWQ"
   },
   "source": [
    "# Similarity and distance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "335kCek2YCWR"
   },
   "source": [
    "scikit-fingerprints implements multiple ways to measure **similarity** or **distance** between molecules, particularly between their fingerprints. Those similarity measures and distance metrics can be used e.g. in searching, clustering, dimentionality reduction, kNN classification, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarities and metrics overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we can divide those measures into two groups, depending on their input:\n",
    "1. Working on molecular fingerprints (vectorized molecules). Different metrics and metric variants are used for binary and count fingerprints.\n",
    "2. Using molecules (RDKit ``Mol`` objects) directly.\n",
    "\n",
    "Most functions are naturally defined as similarities - the higher, the more similar two molecules are. Most similarity functions have a bounded value range, typically [0,1]. Every similarity also has a corresponding distance function implemented, usually equal to `1 - similarity`.\n",
    "\n",
    "Additionally, for batch computation, e.g. pairwise similarity measurements, every metric also has a bulk function, which works on whole matrices (or lists of molecules)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fingerprint similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarities and distances working on fingerprint vectors can be defined for binary or count fingerprints. Most similarities, however, can only be defined for binary fingerprints. This distinction is visible in function names, e.g. `tanimoto_binary_similarity` vs `tanimoto_count_similarity`. Most similarity functions have bounded value range, typically $[0, 1]$.\n",
    "\n",
    "There are two major groups of similarities:\n",
    "- only considering \"on\" bits, i.e. 1s in vector representations\n",
    "- including both \"off\" and \"on\" bits\n",
    "\n",
    "For two binary vectors `x` and `y`, we can define four values, which are used to compute metrics:\n",
    "\n",
    "  - $a$ – $|x \\cap y|$, the number of common \"on\" bits\n",
    "  - $b$ – $|x \\cap \\bar{y}|$, the number of positions where $x$ is 1 and $y$ is 0\n",
    "  - $c$ – $|\\bar{x} \\cap y|$, the number of positions where $x$ is 0 and $y$ is 1\n",
    "  - $d$ – $|\\bar{x} \\cap \\bar{y}|$, the number of positions where both are 0, the number of common \"off\" bits\n",
    "\n",
    "We can also mark $|x|$ as total number of \"on\" bits (1s) in the $x$ vector.\n",
    "\n",
    "[Tanimoto binary similarity](https://scikit-fingerprints.readthedocs.io/latest/modules/generated/skfp.distances.tanimoto_binary_similarity.html) is the most commonly used similarity measure, defined as:\n",
    "\n",
    "  $$\n",
    "  sim(x, y) = \\frac{|x \\cap y|}{|x \\cup y|} = \\frac{|x \\cap y|}{|x| + |y| - |x \\cap y|} = \\frac{a}{a + b + c}\n",
    "  $$\n",
    "\n",
    "[Tanimoto count similarity](https://scikit-fingerprints.readthedocs.io/latest/modules/generated/skfp.distances.tanimoto_count_similarity.html) is an extension to count vectors, utilizing dot product as a measure of \"common bits\", and vector length instead of just sum of 1s. The larger the dot product, the more similar the two vectors are. It is defined as:\n",
    "\n",
    "  $$\n",
    "  sim(x, y) = \\frac{x \\cdot y}{\\|x\\|^2 + \\|y\\|^2 - x \\cdot y}\n",
    "  $$\n",
    "\n",
    "\n",
    "Both variants of Tanimoto similarity use only \"on\" bits. [Rogot-Goldberg similarity](https://scikit-fingerprints.readthedocs.io/latest/modules/generated/skfp.distances.rogot_goldberg_binary_similarity.html) is an example of similarity that includes \"off\" bits information. It works only for binary vectors. It is defined as:\n",
    "\n",
    "  $$\n",
    "  sim(x, y) = \\frac{a}{2 \\times (2a + b + c)} + \\frac{d}{2 \\times (2d + b + c)}\n",
    "  $$\n",
    "\n",
    "Tanimoto similarity in both versions and Rogot-Goldberg similarity have values in range $[0, 1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some code examples of those similarities. Functions take two vectors and output similarity/distance value as a float. NumPy arrays shoule be 1-dimensional vectors, i.e. rows of array after computing fingerprints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tanimoto similarity: 0.33\n",
      "Rogot-Goldberg similarity: 0.50\n",
      "\n",
      "Tanimoto distance: 0.67\n",
      "Rogot-Goldberg similarity: 0.50\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from skfp.distances import (\n",
    "    rogot_goldberg_binary_distance,\n",
    "    rogot_goldberg_binary_similarity,\n",
    "    tanimoto_binary_distance,\n",
    "    tanimoto_binary_similarity,\n",
    ")\n",
    "\n",
    "vec_a = [1, 1, 0, 0]\n",
    "vec_b = [0, 1, 1, 0]\n",
    "\n",
    "vec_a_dense = np.array(vec_a)\n",
    "vec_b_dense = np.array(vec_b)\n",
    "\n",
    "tanimoto_sim = tanimoto_binary_similarity(vec_a_dense, vec_b_dense)\n",
    "tanimoto_dist = tanimoto_binary_distance(vec_a_dense, vec_b_dense)\n",
    "\n",
    "rogot_sim = rogot_goldberg_binary_similarity(vec_a_dense, vec_b_dense)\n",
    "rogot_dist = rogot_goldberg_binary_distance(vec_a_dense, vec_b_dense)\n",
    "\n",
    "print(f\"Tanimoto similarity: {tanimoto_sim:.2f}\")\n",
    "print(f\"Rogot-Goldberg similarity: {rogot_sim:.2f}\")\n",
    "print()\n",
    "print(f\"Tanimoto distance: {tanimoto_dist:.2f}\")\n",
    "print(f\"Rogot-Goldberg similarity: {rogot_dist:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sparse data, SciPy sparse arrays should be in CSR format and have a single row with values. Everything else works exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tanimoto similarity: 0.33\n",
      "Rogot-Goldberg similarity: 0.50\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_array\n",
    "\n",
    "vec_a_sparse = csr_array([vec_a])\n",
    "vec_b_sparse = csr_array([vec_b])\n",
    "\n",
    "tanimoto_sim_sparse = tanimoto_binary_similarity(vec_a_sparse, vec_b_sparse)\n",
    "rogot_sim_sparse = rogot_goldberg_binary_similarity(vec_a_sparse, vec_b_sparse)\n",
    "\n",
    "print(f\"Tanimoto similarity: {tanimoto_sim_sparse:.2f}\")\n",
    "print(f\"Rogot-Goldberg similarity: {rogot_sim_sparse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count variants work exactly the same way as binary ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tanimoto count similarity: 0.88\n",
      "Tanimoto count distance: 0.12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from skfp.distances import tanimoto_count_distance, tanimoto_count_similarity\n",
    "\n",
    "vec_a = [2, 3, 4, 0]\n",
    "vec_b = [2, 3, 4, 2]\n",
    "\n",
    "vec_a_numpy = np.array(vec_a)\n",
    "vec_b_numpy = np.array(vec_b)\n",
    "\n",
    "count_sim_numpy = tanimoto_count_similarity(vec_a_numpy, vec_b_numpy)\n",
    "count_dist_numpy = tanimoto_count_distance(vec_a_numpy, vec_b_numpy)\n",
    "\n",
    "print(f\"Tanimoto count similarity: {count_sim_numpy:.2f}\")\n",
    "print(f\"Tanimoto count distance: {count_dist_numpy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Molecule similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some similarities include molecule structure directly in their calculation. Sometimes they can be more flexible, as they don't lose any information during the fingerprint calculation step.\n",
    "\n",
    "[Fraggle similarity](https://scikit-fingerprints.readthedocs.io/latest/modules/generated/skfp.distances.fraggle_similarity.html) is designed to be less sensitive to small changes in the middle of molecule, compared to fingerprint-based measures. It looks more on the \"overall shape similarity\" of molecules. Its calculation consists of a few steps:\n",
    "- fragment molecule into \"interesting\" substructures by acyclic and ring cuts, leaving only “large” parts of the molecule (>60%)\n",
    "- compare fragments with Tversky similarity, keep only appropriately similar ones\n",
    "- compute [RDKit fingerprints](https://scikit-fingerprints.readthedocs.io/latest/modules/generated/skfp.fingerprints.RDKitFingerprint.html) with path length 5, compare with Tanimoto similarity\n",
    "- largest Tanimoto similarity is the Fraggle similarity value\n",
    "\n",
    "This measure is asymmetric, i.e. `sim(mol_a, mol_b)` can be potentially quite different from `sim(mol_b, mol_a)`. Its value range is $[0, 1]$.\n",
    "\n",
    "[Maximum Common Substructure (MCS) similarity](https://scikit-fingerprints.readthedocs.io/latest/modules/generated/skfp.distances.mcs_similarity.html) checks the size of the maximum common substructure (MCS) between two molecules as their structural overlap, with the formula:\n",
    "\n",
    "$$\n",
    "sim(mol_a, mol_b) = \\frac{numAtoms(MCS(mol_a, mol_b))}{numAtoms(mol_a) + numAtoms(mol_b) - numAtoms(MCS(mol_a, mol_b))}\n",
    "$$\n",
    "\n",
    "It also penalizes difference in molecule sizes. Its value range is $[0, 1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's jump into the code. Here, we use RDKit `Mol` objects, rather than fingerprints. We can see that Fraggle similarity is indeed asymmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraggle similarity query-reference: 0.16\n",
      "Fraggle similarity reference-query: 0.26\n"
     ]
    }
   ],
   "source": [
    "from rdkit.Chem import MolFromSmiles\n",
    "\n",
    "from skfp.distances import fraggle_similarity\n",
    "\n",
    "mol_query = MolFromSmiles(\"COc1cc(CN2CCC(NC(=O)c3cncc(C)c3)CC2)c(OC)c2ccccc12\")\n",
    "mol_ref = MolFromSmiles(\"COc1ccccc1\")\n",
    "\n",
    "fraggle_sim = fraggle_similarity(mol_query, mol_ref)\n",
    "fraggle_sim_reverse = fraggle_similarity(mol_ref, mol_query)\n",
    "\n",
    "print(f\"Fraggle similarity query-reference: {fraggle_sim:.2f}\")\n",
    "print(f\"Fraggle similarity reference-query: {fraggle_sim_reverse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCS similarity is used identically, but it is symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OQNn3USQYCWW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCS similarity query-reference: 0.26\n",
      "MCS similarity reference-query: 0.26\n"
     ]
    }
   ],
   "source": [
    "from skfp.distances import mcs_similarity\n",
    "\n",
    "mcs_sim = mcs_similarity(mol_query, mol_ref)\n",
    "mcs_sim_reverse = mcs_similarity(mol_ref, mol_query)\n",
    "\n",
    "print(f\"MCS similarity query-reference: {mcs_sim:.2f}\")\n",
    "print(f\"MCS similarity reference-query: {mcs_sim_reverse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Shm5FyoRYCWW"
   },
   "source": [
    "## Scikit-learn compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYj_wtiYj5MS"
   },
   "source": [
    "scikit-fingerprints is designed and tested to be fully compatible with scikit-learn. As such, you can use similarity metrics in your ML pipelines, e.g. for [k nearest neighbors classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). Same mechanism would also work for density-based clustering like [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html).\n",
    "\n",
    "Let's see how this works using a kNN classifier on [BACE dataset](https://scikit-fingerprints.readthedocs.io/latest/modules/datasets/generated/skfp.datasets.moleculenet.load_bace.html#skfp.datasets.moleculenet.load_bace). Note that in scikit-learn, the interface expects **distances**, not similarities, so you have to use an appropriate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 74.62%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from skfp.datasets.moleculenet import load_bace\n",
    "from skfp.fingerprints import ECFPFingerprint\n",
    "from skfp.model_selection import scaffold_train_test_split\n",
    "\n",
    "smiles, y = load_bace()\n",
    "smiles_train, smiles_test, y_train, y_test = scaffold_train_test_split(\n",
    "    smiles, y, test_size=0.2\n",
    ")\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ECFPFingerprint(), KNeighborsClassifier(metric=tanimoto_binary_distance)\n",
    ")\n",
    "pipeline.fit(smiles_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(smiles_test)\n",
    "auroc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f\"AUROC: {auroc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use count fingerprint, then we should also switch the metric appropriately. Everything else stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 71.21%\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ECFPFingerprint(count=True), KNeighborsClassifier(metric=tanimoto_count_distance)\n",
    ")\n",
    "pipeline.fit(smiles_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(smiles_test)\n",
    "auroc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f\"AUROC: {auroc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_QHvOIUYCWW"
   },
   "source": [
    "## Bulk similarity computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytahLYPpYCWW"
   },
   "source": [
    "If you need to quickly compute similarity or distance between many vectors, you can use **bulk** variant of a function. Bulk variants are equivalent to scikit-learn's **pairwise distances**, but are much faster, thanks to Numba JIT and optimized representation. Note that they do not support sparse arrays due to Numba limitations.\n",
    "\n",
    "In the example below, the similarity is computed between i-th rows and j-th columns of both arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fUtOB4EAYCWW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66666667, 0.66666667, 1.        ],\n",
       "       [0.5       , 0.5       , 0.33333333],\n",
       "       [0.66666667, 0.66666667, 1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skfp.distances.tanimoto import (\n",
    "    bulk_tanimoto_binary_similarity,\n",
    ")\n",
    "\n",
    "arr_1 = np.array(\n",
    "    [\n",
    "        [1, 1, 1],\n",
    "        [0, 0, 1],\n",
    "        [1, 1, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "arr_2 = np.array(\n",
    "    [\n",
    "        [1, 0, 1],\n",
    "        [0, 1, 1],\n",
    "        [1, 1, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "sim = bulk_tanimoto_binary_similarity(arr_1, arr_2)\n",
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2jSyK4TdYd3"
   },
   "source": [
    "If we pass a single array, then the similarities will be computed between its rows. This is useful for self-similarity computation, e.g. evaluation chemical diversity of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Jt0wjKx7djie"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(\n",
    "    [\n",
    "        [1, 1, 1],\n",
    "        [0, 0, 0],\n",
    "        [1, 1, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "sim = bulk_tanimoto_binary_similarity(X)\n",
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-fingerprints acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugtxVJxSgFIP"
   },
   "source": [
    "Let's see how much scikit-fingerprints with Numba JIT and other optimizations speeds things up. We will compare with a manual nested loop, used by many older projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "U7UsgXGXgaod"
   },
   "outputs": [],
   "source": [
    "from skfp.fingerprints import ECFPFingerprint\n",
    "from skfp.preprocessing import MolFromSmilesTransformer\n",
    "\n",
    "mol_from_smiles = MolFromSmilesTransformer(suppress_warnings=True)\n",
    "smiles, y = load_bace()\n",
    "smiles = smiles[:100]  # subset for speed\n",
    "mols = mol_from_smiles.transform(smiles)\n",
    "\n",
    "fp = ECFPFingerprint(count=True)\n",
    "fps = fp.transform(mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pbGGAxWhhmPt",
    "outputId": "aa6f54cc-5886-4955-c55c-7a671729df41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234 ms ± 9.09 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 3 -n 10 [tanimoto_count_similarity(fps[i], fps[j]) for i in range(len(fps)) for j in range(len(fps))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e9AtjEThn6U",
    "outputId": "e227bf9c-187e-4730-e025-d92f10fd9bf1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 15.38 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "15.7 ms ± 18.4 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 3 -n 10 [bulk_tanimoto_count_similarity(fps, fps)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speedup is visible even on such a small sample. For hundreds or thousands of compounds the time performance can be improved by several orders of magnitude."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
